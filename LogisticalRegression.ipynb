{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticalRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQSXG1lvZgL5"
      },
      "source": [
        "# Import our data here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import requests\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "mal_data = pd.read_csv('malicious_phish.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA5kvN2rC_r0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x6GySo6ZIEu"
      },
      "source": [
        "# Rules for to implement, or \"flags\"\n",
        "# 1.  If url contains \"%00\" \n",
        "def containsPercent00(str):\n",
        "  if str.find(\"%00\"):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# 2.  If url contains \"%01\"\n",
        "def containsPercent01(str):\n",
        "  if str.find(\"%01\"):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# 3.  If url contains '-' if more than four, then fradulent\n",
        "def containsFourDash(str):\n",
        "  if str.count(\"-\") == 4:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "# 4.  If (perform get request) url returned != url sent \n",
        "def checkIf_URLsent_equals_getURL(str):\n",
        "  temp = (requests.head(\"http://\"+str).headers['location'])\n",
        "  if temp != str:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# 5.  If url contains more than one instance of \"http://\"\n",
        "def containsMoreHttp(str):\n",
        "  if str.count(\"http://\") > 1:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "# 6.  If url contains more than one instance of \"https://\"\n",
        "def containsMoreHttps(str):\n",
        "  if str.count(\"https://\") > 1:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# 7.  If url contains \"http://\" AND \"https://\"\n",
        "def containsHttpAndHttps(str):\n",
        "  if \"http://\" in str and \"https://\" in str:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "\n",
        "# 8.  If url is over 54 characters\n",
        "def over54Chars(str):\n",
        "  if len(str) > 54:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "# 9.  If url has more than one instance of a domain extension\n",
        "def hasMoreExtension(str):\n",
        "  if \".com\" in str and \".net\" in str and \".org\" in str:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "# 10. If url does not contain \"https://\"\n",
        "def doesNotContainHttps(str):\n",
        "  if \"https://\" not in str:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# 11. If url contains \"index.php\"\n",
        "def overIndexPhp(str):\n",
        "  if str.find(\"index.php\"):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# 12. If url has \"@\"\n",
        "def hasAt(str):\n",
        "  if \"@\" in str:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# 13. If url has \"//\" after seventh position\n",
        "def hasTwoSlash(str):\n",
        "  if str.find(\"//\")!=-1 and str.find(\"//\")>7:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "  \n",
        "# 14. If url has multiple subdomains  \n",
        "def hasMultDom(str):\n",
        "  dom = re.search(\"(?<=:\\/\\/)[^/]*\", str)\n",
        "  if(not dom): return 0\n",
        "  if(dom.group(0).count(\".\")>2): return 1\n",
        "  return 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUBnaRQbaVnx"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "\n",
        "#reading from sample file with file upload(in sidebar)\n",
        "df = pd.read_csv('sample2.csv')\n",
        "#making pipeline to extract and adjust features for training\n",
        "url_list = df.url\n",
        "pipe = Pipeline(\n",
        "    [\n",
        "     ('count',CountVectorizer()),\n",
        "     ('tfidf',TfidfTransformer()),\n",
        "     ('scale',StandardScaler(with_mean=False)),\n",
        "     ('feature selection', VarianceThreshold())\n",
        "     ])\n",
        "pipe.fit(url_list)\n",
        "Xa = pipe.transform(url_list)\n",
        "#using above flags for 11 other features\n",
        "Xb = []\n",
        "for i in range(0,url_list.size):\n",
        "    new = []\n",
        "    new.append(containsPercent00(url_list[i]))\n",
        "    new.append(containsPercent01(url_list[i]))\n",
        "    new.append(containsFourDash(url_list[i]))\n",
        "    #new.append(checkIf_URLsent_equals_getURL(url_list[i]))\n",
        "    new.append(containsMoreHttp(url_list[i]))\n",
        "    new.append(containsMoreHttps(url_list[i]))\n",
        "    new.append(over54Chars(url_list[i]))\n",
        "    new.append(hasMoreExtension(url_list[i]))\n",
        "    new.append(doesNotContainHttps(url_list[i]))\n",
        "    new.append(overIndexPhp(url_list[i]))\n",
        "    new.append(hasAt(url_list[i]))\n",
        "    new.append(hasTwoSlash(url_list[i]))\n",
        "    new.append(hasMultDom(url_list[i]))\n",
        "    Xb.append(new)\n",
        "#cocatenating the two feature matrices\n",
        "X = hstack([Xa,csr_matrix(Xb)])\n",
        "#generating labels from data\n",
        "result = df.type\n",
        "y = []\n",
        "for i in range (0,result.size):\n",
        "    if result[i]==\"benign\": y.append(0)\n",
        "    else: y.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRSFrKbJhSoJ",
        "outputId": "f75e2c75-2ab9-44da-a8ff-1d6a5a67d494"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#splitting into test and train sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0,test_size=.3)\n",
        "#using sci kit learn's logistic regression function to create a model\n",
        "clf=LogisticRegression(random_state=0,max_iter=1000000000000).fit(X_train,y_train)\n",
        "print(\"accuracy of logistic regression:\")\n",
        "print(clf.score(X_test,y_test))\n",
        "print(\"precision:\")\n",
        "print(precision_score(y_test,clf.predict(X_test)))\n",
        "print(\"AUC:\")\n",
        "print(roc_auc_score(y_test,clf.predict(X_test)))\n",
        "print(\"Recall:\")\n",
        "print(recall_score(y_test,clf.predict(X_test)))\n",
        "print(\"F1:\")\n",
        "print(f1_score(y_test,clf.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of logistic regression:\n",
            "0.9246666666666666\n",
            "precision:\n",
            "0.9921875\n",
            "AUC:\n",
            "0.8470641482107296\n",
            "Recall:\n",
            "0.6958904109589041\n",
            "F1:\n",
            "0.8180354267310789\n"
          ]
        }
      ]
    }
  ]
}